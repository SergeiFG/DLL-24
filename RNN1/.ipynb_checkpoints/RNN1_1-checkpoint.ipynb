{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f3050e-fa8b-482a-b44e-8bc3e60d3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchinfo import summary\n",
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc848ff3-ee3e-45f0-b2a3-c895601f022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_split_sentences(file_path, file_path2):\n",
    "    # Чтение содержимого файла\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Приведение текста к нижнему регистру\n",
    "    content = content.lower()\n",
    "\n",
    "    # Удаление нежелательных символов и знаков препинания\n",
    "    content = re.sub(r'[^а-яА-Я0-9\\s\\.?!]', '', content)\n",
    "\n",
    "    # Удаление лишних пробелов и пробельных символов\n",
    "    content = re.sub(r'\\s+', ' ', content)\n",
    "    \n",
    "    # Разделение текста на предложения\n",
    "    sentences = re.split(r'[.!?]', content)\n",
    "\n",
    "    # Удаление пустых предложений\n",
    "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "    # Запись нормализованных предложений в файл\n",
    "    with open(file_path2, 'w') as file:\n",
    "        file.write('\\n'.join(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4b6985-2746-4793-bf9f-baf91c417192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = 'text_raw.txt'\n",
    "normalize_and_split_sentences(file_path, 'text_new.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b834035-f461-4180-a073-c8727fd2c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = 'абвгдежзийклмнопрстуфхцчшщьыъэюя1234567890 '\n",
    "INDEX_TO_CHAR =  [w for w in CHARS] + ['none']\n",
    "CHARS_NUM = len(INDEX_TO_CHAR)\n",
    "CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}\n",
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d4de11-635a-43ef-afa5-a6b97b32938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ceasar(line, shift):\n",
    "    index_line = ['none']*MAX_LENGTH\n",
    "    for i in range(min(len(line), MAX_LENGTH)):\n",
    "        index_line[i] = line[i]\n",
    "    index_line = list(map(lambda x: CHAR_TO_INDEX.get(x, CHAR_TO_INDEX['none']), index_line))    \n",
    "    for i, ch in enumerate(index_line):\n",
    "        if ch not in [CHARS_NUM-1, CHARS_NUM-2]:\n",
    "            index_line[i] = (ch + shift) % (len(INDEX_TO_CHAR)-2)\n",
    "    return torch.tensor(index_line, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ab6e0b-2432-4b14-bcb7-a7246ce0ae1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40])\n",
      "[' ', 'г', 'д', 'е', 'ж', ' ', '1', '2', '3', ' ', 'а', 'б', 'в', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none']\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "res = Ceasar(' абвг эюя 890', 3)\n",
    "print(res.shape)\n",
    "print(list(map(lambda x: INDEX_TO_CHAR[x], res)))\n",
    "print(res.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b8b0d22-910c-45a5-888d-e0dc973910d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data_raw = []\n",
    "with open('text_new.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        K = random.randint(1, CHARS_NUM-3)\n",
    "        Data_raw.append(tuple([Ceasar(line, K), Ceasar(line, 0)]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02623083-1114-4ab9-b15c-a9ce289b81f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_train, Data_test = train_test_split(Data_raw, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbc217a5-1e93-4244-96b9-708486ae5c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([20, 15, 17, 25, 21, 42, 20, 12, 42, 14, 20,  7, 12, 25, 42, 22, 23, 21,\n",
       "         42,  8, 26, 20, 29, 18,  7, 26, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "         43, 43, 43, 43]),\n",
       " tensor([13,  8, 10, 18, 14, 42, 13,  5, 42,  7, 13,  0,  5, 18, 42, 15, 16, 14,\n",
       "         42,  1, 19, 13, 22, 11,  0, 19, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,\n",
       "         43, 43, 43, 43]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_train[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e1a6b81-7a0c-4e92-91ea-3b7eb81e5f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = torch.utils.data.DataLoader(Data_train, batch_size=10, shuffle=True)\n",
    "Test = torch.utils.data.DataLoader(Data_test, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2715b386-312d-4ddd-9a19-82e961de5eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "check = 'здесь мы проверяем качество работы'\n",
    "print(len(check))\n",
    "def test_sentence(test_sentence):\n",
    "    # K = random.randint(1, CHARS_NUM-3)\n",
    "    K = random.randint(1, 15)\n",
    "    return Ceasar(test_sentence, K).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da1c283b-21da-4a8c-8806-4dd2937a5ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 40])\n",
      "torch.int64\n",
      "tensor([[13, 10, 11, 23, 32, 42, 18, 33, 42, 21, 22, 20,  8, 11, 22, 37, 11, 18,\n",
      "         42, 16,  6, 29, 11, 23, 24,  8, 20, 42, 22,  6,  7, 20, 24, 33, 43, 43,\n",
      "         43, 43, 43, 43]])\n"
     ]
    }
   ],
   "source": [
    "print(test_sentence(check).shape)\n",
    "print(test_sentence(check).dtype)\n",
    "print(test_sentence(check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02933f7e-e137-44b8-af5f-cfaf779cdfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 40])\n",
      "у р с э 7   ш 8   ы ъ ь о с ъ б с ш   ц м 4 с э ю о ь   ъ м н ь ю 8 none none none none none none\n"
     ]
    }
   ],
   "source": [
    "res = test_sentence(check)\n",
    "print(res.shape)\n",
    "print(*list(map(lambda x: INDEX_TO_CHAR[x], res.squeeze())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8028a203-549a-48cf-8e19-74bcb6450284",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.embed = torch.nn.Embedding(CHARS_NUM, 400)\n",
    "        self.rnn = torch.nn.RNN(400, 1000, batch_first=True, nonlinearity='relu')\n",
    "        self.linear = torch.nn.Linear(1000, CHARS_NUM)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, sentences, state=None):\n",
    "        embed = self.embed(sentences)\n",
    "        o, s = self.rnn(embed)\n",
    "        fc = self.linear(o)\n",
    "        out = self.softmax(fc)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d833fe6-d159-4a7d-91d4-505dcee8a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3f775cc-eb89-4761-adbb-419d6df29858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Network                                  [1, 40, 44]               --\n",
       "├─Embedding: 1-1                         [1, 40, 400]              17,600\n",
       "├─RNN: 1-2                               [1, 40, 1000]             1,402,000\n",
       "├─Linear: 1-3                            [1, 40, 44]               44,044\n",
       "├─Softmax: 1-4                           [1, 40, 44]               --\n",
       "==========================================================================================\n",
       "Total params: 1,463,644\n",
       "Trainable params: 1,463,644\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 56.14\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.46\n",
       "Params size (MB): 5.85\n",
       "Estimated Total Size (MB): 6.32\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, test_sentence(check).shape, dtypes=['torch.IntTensor'], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7635238-afeb-46b2-8ebd-7417888fa88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap(batch):\n",
    "    new_batch = torch.zeros(list(batch.shape) + [CHARS_NUM])\n",
    "    for i, sentence in enumerate(batch):\n",
    "        for j, ch in enumerate(sentence):\n",
    "            new_batch[i][j][int(ch)] = 1\n",
    "    return new_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad374ffc-d0e0-4b3e-9d4b-84c69b2d1eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss =  3.3536601066589355 ,  3.3537771701812744\n",
      "Initial Accuracy =  0.0009900205924283226 %,  0.0039594551789673745 %\n",
      "Done  1  of  15  which is  7 %\n",
      "Loss =  0.33049261282953013 ,  0.32960900476472\n",
      "Accuracy =  32.52257246950737 ,  39.57079505859994\n",
      "Тестовое предложение на эпохе:\n",
      "я 2 р ц и   ф ы   ч о г ъ 0 л 5 8 и   б е 3 8 ш ь й г   д е 3 т ь и none none none none none none\n",
      "None\n",
      "Done  2  of  15  which is  14 %\n",
      "Loss =  0.32695602082836067 ,  0.32460440628733256\n",
      "Accuracy =  37.92709488357358 ,  43.26259106746912\n",
      "Тестовое предложение на эпохе:\n",
      "я 2 6 ъ ч   1 щ   м о р г б л ы ю и   ъ д ц 0 0 н й 8   с е 3 0 ш ь none none none none none none\n",
      "None\n",
      "Done  3  of  15  which is  20 %\n",
      "Loss =  0.32157798818376465 ,  0.3193069900709653\n",
      "Accuracy =  46.21752732456835 ,  49.275419702248975\n",
      "Тестовое предложение на эпохе:\n",
      "1 9 6 ъ 4   ф 0   х т о а ж л ю й и   к 2 ч 5 с р а л   н а б т т ь none none none none none none\n",
      "None\n",
      "Done  4  of  15  which is  27 %\n",
      "Loss =  0.31666789696142184 ,  0.31535791021606235\n",
      "Accuracy =  51.740456201488996 ,  53.32831802343997\n",
      "Тестовое предложение на эпохе:\n",
      "1 9 6 ъ ь   1 8   п р о в ж 8 я е й   з а ч д с т г н   4 э б н у ы none none none none none none\n",
      "None\n",
      "Done  5  of  15  which is  34 %\n",
      "Loss =  0.3130725462992218 ,  0.3124047302920342\n",
      "Accuracy =  55.22810074449549 ,  57.41051631295534\n",
      "Тестовое предложение на эпохе:\n",
      "1 9 2 ш ю 7 ф 8   х т п в ж с 5 е м   и а ч е с ж г о   п а б р у ы none none none none none none\n",
      "None\n",
      "Done  6  of  15  which is  40 %\n",
      "Loss =  0.31001716588768247 ,  0.3101439376325973\n",
      "Accuracy =  59.96356724219864 ,  60.456921127652826\n",
      "Тестовое предложение на эпохе:\n",
      "1 9 6 ъ ь   и х   п р о д ж л я е м   к а щ д с т в л   н г б л т ы none none none none none none\n",
      "None\n",
      "Done  7  of  15  which is  47 %\n",
      "Loss =  0.3084264348808227 ,  0.30887023965354055\n",
      "Accuracy =  62.03865040392841 ,  62.321824516946464\n",
      "Тестовое предложение на эпохе:\n",
      "7 н 6 0 ь   з щ   4 р м а ж 8 э г к   4 3 ч е с у в о   р а б о ф ы none none none none none none\n",
      "None\n",
      "Done  8  of  15  which is  54 %\n",
      "Loss =  0.30785937307754485 ,  0.3087439309731291\n",
      "Accuracy =  62.94610327894821 ,  62.128603104212864\n",
      "Тестовое предложение на эпохе:\n",
      "1 0 6 ш х   у 4   з 0 п г ж л я е м   к а ч и с ф в о   р 2 б л т ы none none none none none none\n",
      "None\n",
      "Done  9  of  15  which is  60 %\n",
      "Loss =  0.3080894261027372 ,  0.31034772872622723\n",
      "Accuracy =  61.37395057817202 ,  56.4562876148242\n",
      "Тестовое предложение на эпохе:\n",
      "1 6 6 ы ц   4 8   э 0 п д ж 0 5 е м   к а ш и с т в о   р а б о ф ъ none none none none none none\n",
      "None\n",
      "Done  10  of  15  which is  67 %\n",
      "Loss =  0.30710214233881844 ,  0.30783739458506415\n",
      "Accuracy =  61.5939331538096 ,  61.67168197656003\n",
      "Тестовое предложение на эпохе:\n",
      "э 5 0 9 4   4 ю   з 0 8 д е н я е м   к а ч и с т в л   у а б о ф ы none none none none none none\n",
      "None\n",
      "Done  11  of  15  which is  74 %\n",
      "Loss =  0.3069435637895683 ,  0.3082467335328521\n",
      "Accuracy =  62.28952162204974 ,  60.72062084257206\n",
      "Тестовое предложение на эпохе:\n",
      "1 н 2 9 х   п ю   п р 8 д е р я е м   к 9 ч и с т в о   р а б 8 ф ы none none none none none none\n",
      "None\n",
      "Done  12  of  15  which is  80 %\n",
      "Loss =  0.3069285703653317 ,  0.3107996953602339\n",
      "Accuracy =  61.566014573103125 ,  57.83813747228381\n",
      "Тестовое предложение на эпохе:\n",
      "1 5 6 9 щ   и х   п р 8 7 г у 5 7 й   з 9 ч д с ф в о   н а б о т ы none none none none none none\n",
      "None\n",
      "Done  13  of  15  which is  87 %\n",
      "Loss =  0.3068696495547416 ,  0.30884012648830467\n",
      "Accuracy =  62.747505148107074 ,  60.45612923661704\n",
      "Тестовое предложение на эпохе:\n",
      "1 ю 0 9 щ   и ь   о п 8 д ж у я з м   к 2 ш з с т в л   р а б о з ы none none none none none none\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[0;32m     40\u001b[0m l \u001b[38;5;241m=\u001b[39m criterion(y_pred, unwrap(Y))\n\u001b[1;32m---> 41\u001b[0m \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     44\u001b[0m ep_hist_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m l\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_num = 15\n",
    "hist_train = np.array([])\n",
    "hist_test = np.array([])\n",
    "acc_train = np.array([])\n",
    "acc_test = np.array([])\n",
    "\n",
    "for X, Y in Train:\n",
    "    ep_hist_train, ep_acc_train = 0, 0\n",
    "    y_pred = model(X)\n",
    "    l = criterion(y_pred, unwrap(Y))\n",
    "    ep_hist_train += l.item()\n",
    "    ep_acc_train += (y_pred.argmax(dim=2) == Y).sum().item()\n",
    "    \n",
    "for X, Y in Test:\n",
    "    ep_hist_test, ep_acc_test = 0, 0\n",
    "    y_pred = model(X)\n",
    "    l = criterion(y_pred, unwrap(Y))\n",
    "    ep_hist_test += l.item()\n",
    "    ep_acc_test += (y_pred.argmax(dim=2) == Y).sum().item()\n",
    "    \n",
    "hist_train = np.append(hist_train, ep_hist_train)\n",
    "hist_test = np.append(hist_test, ep_hist_test)\n",
    "acc_train = np.append(acc_train, ep_acc_train/len(Data_train)/MAX_LENGTH*100)\n",
    "acc_test = np.append(acc_test, ep_acc_test/len(Data_test)/MAX_LENGTH*100)\n",
    "\n",
    "print('Initial Loss = ', hist_train[-1], ', ', hist_test[-1])\n",
    "print('Initial Accuracy = ', acc_train[-1], '%, ', acc_test[-1], '%')\n",
    "\n",
    "check_data = test_sentence(check)\n",
    "\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    \n",
    "    ep_hist_train, ep_hist_test = 0, 0\n",
    "    ep_acc_train, ep_acc_test = 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    for X, Y in Train:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        l = criterion(y_pred, unwrap(Y))\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ep_hist_train += l.item()\n",
    "        ep_acc_train += (y_pred.argmax(dim=2) == Y).sum().item()\n",
    "    \n",
    "    model.eval()\n",
    "    for X, Y in Test:\n",
    "        y_pred = model(X)\n",
    "        l = criterion(y_pred, unwrap(Y))\n",
    "        \n",
    "        ep_hist_test += l.item()\n",
    "        ep_acc_test += (y_pred.argmax(dim=2) == Y).sum().item()\n",
    "    \n",
    "    hist_train = np.append(hist_train, ep_hist_train/len(Data_train))\n",
    "    hist_test = np.append(hist_test, ep_hist_test/len(Data_test))\n",
    "    acc_train = np.append(acc_train, ep_acc_train/len(Data_train)/MAX_LENGTH*100)\n",
    "    acc_test = np.append(acc_test, ep_acc_test/len(Data_test)/MAX_LENGTH*100)\n",
    "    \n",
    "\n",
    "    print('Done ', epoch, ' of ', epoch_num, ' which is ', \n",
    "            math.ceil(epoch/epoch_num*100), '%')\n",
    "    print('Loss = ', hist_train[-1], ', ', hist_test[-1])\n",
    "    print('Accuracy = ', acc_train[-1], ', ', acc_test[-1])\n",
    "    check_result = model(check_data).argmax(dim=2)\n",
    "    print('Тестовое предложение на эпохе:')\n",
    "    print(print(*list(map(lambda x: INDEX_TO_CHAR[x], check_result.squeeze()))))\n",
    "    \n",
    "\n",
    "print('Training Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e178bf-8a1c-44ee-bb95-40559633137c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cc895b-1856-4c2d-900d-03b560282816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
